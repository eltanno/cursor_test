# Cursor Test - AI Agent Development Workspace

A learning project for understanding Cursor AI agents with opinionated development workflows, automated planning documentation, and GitHub Kanban integration.

## ğŸ¯ Project Goals

This repository demonstrates:

1. **Planning-First Development**: All features start with comprehensive planning documents
2. **Test-Driven Development (TDD)**: Red â†’ Green â†’ Refactor workflow
3. **Automated Ticket Management**: GitHub Issues integrated with Kanban board
4. **Best Practices Enforcement**: Opinionated rules ensure code quality
5. **Git Workflow**: Feature branches with PR approval process

## ğŸ“‹ Table of Contents

- [Quick Start](#quick-start)
- [Development Workflow](#development-workflow)
- [Project Structure](#project-structure)
- [GitHub Integration](#github-integration)
- [Scripts Reference](#scripts-reference)
- [Cursor Rules](#cursor-rules)
- [Contributing](#contributing)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Git
- GitHub account with access to this repository
- GitHub Personal Access Token (see [Setup](#setup))

### Setup

1. **Clone the repository**

```bash
git clone https://github.com/eltanno/cursor_test.git
cd cursor_test
```

2. **Run the setup script (Recommended)**

```bash
./setup.sh
```

This script will:
- Create a Python virtual environment
- Upgrade pip
- Install all dependencies

**Or manually:**

```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate  # On Linux/Mac
# OR
venv\Scripts\activate     # On Windows

# Install dependencies
pip install -r requirements.txt
```

3. **Configure environment variables**

Copy `.env.example` to `.env` and add your GitHub token:

```bash
cp .env.example .env
```

Edit `.env` and add your token:

```env
GITHUB_API_KEY=ghp_your_token_here
GITHUB_OWNER=eltanno
GITHUB_REPO=cursor_test
GITHUB_PROJECT_NUMBER=1
```

4. **Create GitHub Personal Access Token**

- Go to: https://github.com/settings/tokens
- Click "Generate new token (classic)"
- Select scopes: `repo`, `workflow`, `admin:org`, `project`
- Copy token to `.env` file

5. **Activate virtual environment (if not already active)**

```bash
source venv/bin/activate  # On Linux/Mac
# OR
venv\Scripts\activate     # On Windows
```

6. **Verify setup**

```bash
python -c "from scripts.utils.github_api import GitHubAPI; api = GitHubAPI(); print('âœ“ Setup successful!')"
```

> **Note**: Always activate the virtual environment before working on the project or running scripts.

## ğŸ”„ Development Workflow

### Overview

```
Plan â†’ Create Tickets â†’ Implement (TDD) â†’ Review â†’ Test â†’ Done
```

### Detailed Workflow

#### 1. Planning Phase

When requesting a new feature, use planning keywords:

```
"Can you plan a user authentication system?"
```

The AI agent will:
- Create a planning document in `docs/planning/features/`
- Analyze best practices
- Identify reusable components
- **NOT write any code** until you approve

Planning document includes:
- Overview & business value
- Requirements (functional & non-functional)
- Architecture design
- Implementation tasks
- Test strategy
- Dependencies & risks

#### 2. Approval & Ticket Creation

Once you approve the plan:

```
"Proceed with implementation"
```

The agent will:
- Break plan into discrete tasks
- Create GitHub Issues for each task
- Add all issues to **Backlog** column
- Wait for you to move tickets to **Ready**

Or manually create tickets:

```bash
python scripts/github/create_tickets.py docs/planning/features/FEAT-001-example.md
```

#### 3. Implementation Phase

**Your action**: Move ticket from Backlog to **Ready** column

The agent will:
1. Check **Ready** column for work
2. Verify dependencies are met
3. Move ticket to **In Progress**
4. Create feature branch
5. Follow TDD workflow:
   - Write failing tests (RED)
   - Implement minimal code (GREEN)
   - Refactor (REFACTOR)
6. Run all tests (must pass 100%)
7. Commit to feature branch
8. Create PR linked to issue
9. Move ticket to **In Review**
10. Wait for your approval

#### 4. Review Phase

**Your action**: Review the PR

- Review code changes
- Check test coverage
- Approve or request changes
- Move ticket to **In Testing** when approved

#### 5. Testing Phase (PRIORITY)

The agent will:
1. Check **In Testing** column (highest priority)
2. Pull latest changes
3. Run comprehensive test suite
4. **If tests pass**:
   - Move ticket to **Done**
   - Close issue
   - Add test results comment
5. **If tests fail**:
   - Move ticket to **Test Failed**
   - Add detailed failure report
   - Wait for your review

#### 6. Test Failure Handling

**Your action**: Review **Test Failed** tickets

- Review failure details
- Decide on fix approach
- Move back to **Ready** when ready

## ğŸ“ Project Structure

```
cursor_test/
â”œâ”€â”€ .cursorrules              # AI agent behavior rules
â”œâ”€â”€ .env                      # Environment variables (gitignored)
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # This file
â”‚
â”œâ”€â”€ docs/                   # All documentation
â”‚   â””â”€â”€ planning/          # Planning documents
â”‚       â”œâ”€â”€ features/      # Feature planning docs
â”‚       â”‚   â””â”€â”€ template.md
â”‚       â”œâ”€â”€ architecture/  # Architecture Decision Records
â”‚       â”œâ”€â”€ designs/       # UI/UX mockups, diagrams
â”‚       â”‚   â”œâ”€â”€ ui-mockups/
â”‚       â”‚   â””â”€â”€ data-models/
â”‚       â””â”€â”€ workflows/     # Process documentation
â”‚           â””â”€â”€ kanban-workflow.md
â”‚
â”œâ”€â”€ scripts/               # Automation scripts
â”‚   â”œâ”€â”€ github/           # GitHub integration scripts
â”‚   â”‚   â”œâ”€â”€ create_tickets.py
â”‚   â”‚   â”œâ”€â”€ update_ticket.py
â”‚   â”‚   â”œâ”€â”€ check_dependencies.py
â”‚   â”‚   â””â”€â”€ post_test_results.py
â”‚   â””â”€â”€ utils/            # Utility modules
â”‚       â””â”€â”€ github_api.py
â”‚
â”œâ”€â”€ src/                  # Source code (your application)
â”‚   â”œâ”€â”€ core/            # Core business logic
â”‚   â”œâ”€â”€ services/        # External service integrations
â”‚   â”œâ”€â”€ models/          # Data models
â”‚   â”œâ”€â”€ utils/           # Utility functions
â”‚   â”œâ”€â”€ api/             # API endpoints/routes
â”‚   â””â”€â”€ config/          # Configuration
â”‚
â””â”€â”€ tests/               # All tests
    â”œâ”€â”€ unit/           # Unit tests
    â”œâ”€â”€ integration/    # Integration tests
    â””â”€â”€ e2e/           # End-to-end tests
```

## ğŸ”— GitHub Integration

### Kanban Board Columns

| Column | Purpose | Who Manages |
|--------|---------|-------------|
| **Backlog** | New tickets from approved plans | Agent creates |
| **Ready** | Work ready to start | User moves here |
| **In Progress** | Active development | Agent manages |
| **In Review** | PR created, awaiting review | Agent moves, User reviews |
| **In Testing** | Comprehensive testing | Agent tests |
| **Test Failed** | Tests failed, needs fixes | Agent reports, User triages |
| **Done** | Completed & verified | Agent completes |

### Work Prioritization

Agents prioritize in this order:

1. **HIGHEST**: Tickets in **In Testing** column
2. **SECOND**: Tickets in **Ready** column (respecting dependencies)
3. **Labels**: `priority:high` > `priority:medium` > `priority:low`

### Ticket Labels

- `feature` - New functionality
- `bugfix` - Bug fixes
- `testing` - Test-specific work
- `documentation` - Documentation updates
- `refactor` - Code improvements
- `blocked` - Cannot proceed (dependency issue)
- `priority:high` / `priority:medium` / `priority:low`

## ğŸ› ï¸ Scripts Reference

### Create Tickets from Planning Document

```bash
python scripts/github/create_tickets.py docs/planning/features/FEAT-001-example.md
```

Creates GitHub Issues from an approved planning document and adds them to Backlog.

### Update Ticket Status

```bash
python scripts/github/update_ticket.py <issue-number> "<column-name>" "[comment]"
```

Examples:
```bash
python scripts/github/update_ticket.py 123 "In Progress" "Starting work"
python scripts/github/update_ticket.py 456 "Done" "All tests passing"
```

### Check Dependencies

```bash
python scripts/github/check_dependencies.py <issue-number>
```

Verifies all dependency issues are closed before starting work.

Returns:
- Exit code 0: Dependencies met
- Exit code 1: Unmet dependencies

### Post Test Results

```bash
python scripts/github/post_test_results.py <issue-number> <pass|fail> [test-output-file]
```

Examples:
```bash
python scripts/github/post_test_results.py 123 pass test_results.txt
python scripts/github/post_test_results.py 456 fail test_results.txt
```

Posts test results and moves ticket to Done (pass) or Test Failed (fail).

## ğŸ“œ Cursor Rules

This project uses `.cursorrules` to guide AI agent behavior. Key principles:

### Planning Keywords (No Code Written)

When you use these keywords, agents will **only create plans**:
- "plan"
- "design"
- "architect"
- "outline"
- "propose"

### Implementation Keywords (Write Code)

These keywords trigger implementation:
- "implement"
- "proceed"
- "go ahead"
- "create"
- "build"

### Core Principles

1. **Planning First**: All features start with documented plans
2. **Best Practices Analysis**: Plans evaluate if request follows best practices
3. **Reusability Check**: Plans identify existing code to reuse
4. **TDD Always**: Red â†’ Green â†’ Refactor
5. **Test Before Commit**: 100% of tests must pass
6. **Feature Branches**: Never commit to main
7. **PR Approval**: Never merge without user approval
8. **GitHub Integration**: Automated ticket management

### Agent Guardrails

**Agents WILL:**
- âœ… Create comprehensive planning documents
- âœ… Evaluate best practices and suggest alternatives
- âœ… Look for reusable code
- âœ… Work in feature branches
- âœ… Write tests before implementation
- âœ… Run all tests before committing
- âœ… Create PRs and wait for approval
- âœ… Prioritize In Testing column
- âœ… Document test failures thoroughly

**Agents WON'T:**
- âŒ Write code during planning phase
- âŒ Commit directly to main/master
- âŒ Commit with failing tests
- âŒ Merge PRs without approval
- âŒ Ignore best practices without discussion
- âŒ Duplicate code unnecessarily
- âŒ Start work with unmet dependencies

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/unit/test_example.py

# Run with verbose output
pytest -v
```

### Test Structure

```
tests/
â”œâ”€â”€ unit/           # Fast, isolated tests
â”œâ”€â”€ integration/    # Tests with databases, APIs
â””â”€â”€ e2e/           # Full user flow tests
```

### Test Requirements

- **Minimum 90% code coverage**
- All happy paths covered
- All edge cases covered
- All error conditions covered
- Clear, descriptive test names

### Test Naming Convention

```python
def test_<function>_<scenario>_<expected_result>():
    """Test description following Given-When-Then pattern."""
    # Given: Setup
    # When: Action
    # Then: Assert
```

## ğŸ¨ Code Style

### Python

- **PEP 8** compliant
- **Black** formatter (88 char line length)
- **Type hints** on all function signatures
- **Docstrings** (Google style) on all public functions
- **f-strings** for string formatting

### Git Commits

Follow conventional commits:

```
<type>(<scope>): <description>

[optional body]

[optional footer]
```

Types:
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation
- `test`: Tests
- `refactor`: Code refactoring
- `chore`: Maintenance

Examples:
```
feat(auth): add JWT token generation
fix(api): handle null user in endpoint
docs(readme): update installation steps
test(user): add edge case tests
```

## ğŸ¤ Contributing

### For Learning & Practice

This is a learning project for understanding Cursor AI agents. Feel free to:

1. Fork the repository
2. Experiment with the workflow
3. Modify `.cursorrules` to suit your preferences
4. Share your learnings!

### Workflow for Contributors

1. Request a feature using planning keywords
2. Review and approve the generated plan
3. Let the agent create tickets
4. Move tickets to Ready when you want them implemented
5. Review PRs and move to In Testing
6. Agent runs tests and moves to Done or Test Failed

## ğŸ“š Additional Resources

- [Cursor Documentation](https://cursor.sh/docs)
- [GitHub Projects API](https://docs.github.com/en/issues/planning-and-tracking-with-projects)
- [GitHub REST API](https://docs.github.com/en/rest)
- [Conventional Commits](https://www.conventionalcommits.org/)
- [Test-Driven Development](https://testdriven.io/)

## ğŸ“ License

This is a learning project. Feel free to use and modify as needed.

## ğŸ™ Acknowledgments

Created to learn and demonstrate:
- Cursor AI agent capabilities
- Automated development workflows
- GitHub API integration
- Test-driven development
- Planning-first approach

---

**Project URL**: https://github.com/eltanno/cursor_test  
**Kanban Board**: https://github.com/users/eltanno/projects/1  
**Last Updated**: 2025-12-25

